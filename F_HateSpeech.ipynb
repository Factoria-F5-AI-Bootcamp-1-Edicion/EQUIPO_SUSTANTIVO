{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__tWuBFVG07Z"
      },
      "source": [
        "Instalar depencencias y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syKP5knOHPU9",
        "outputId": "c663cc4a-538c-4178-e7d7-52a935038e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 8.4 kB/s \n",
            "\u001b[?25h  Downloading tensorflow_gpu-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 6.9 kB/s \n",
            "\u001b[?25h  Downloading tensorflow_gpu-2.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.8 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=603a41230ae09b2fda505299b277dcb1102853a163b680885b9dcc800f909317\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: tensorflow-gpu, sklearn\n",
            "Successfully installed sklearn-0.0.post1 tensorflow-gpu-2.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow-gpu pandas sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrup3dXL45LZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicional\n",
        "!install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFcj5PzN6FY3",
        "outputId": "2383c58e-ad2c-4594-b8a2-50c3a52f6114"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "install: missing destination file operand after 'h5py'\n",
            "Try 'install --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uBhoBuHo6NBL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VnvBvxo9xAU",
        "outputId": "0e812b6f-f51d-4e22-e224-489c178c7ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IFCfU_6yMHFM",
        "outputId": "03a27ab6-15c4-4b7b-aef4-9b7b2e388907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Factoria F5/youtoxic/youtoxic_english_1000.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "os.path.join(\"/content/drive/MyDrive/Factoria F5/youtoxic/youtoxic_english_1000.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NbXdK3sP-dOw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join(\"/content/drive/MyDrive/Factoria F5/youtoxic/youtoxic_english_1000.csv\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "1GOG4X8l-z20",
        "outputId": "25edd9bd-1331-4c3c-a908-7d7cccdc00b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              CommentId      VideoId  \\\n",
              "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
              "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
              "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
              "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
              "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
              "\n",
              "                                                Text  IsToxic  IsAbusive  \\\n",
              "0  If only people would just take a step back and...    False      False   \n",
              "1  Law enforcement is not trained to shoot to app...     True       True   \n",
              "2  \\nDont you reckon them 'black lives matter' ba...     True       True   \n",
              "3  There are a very large number of people who do...    False      False   \n",
              "4  The Arab dude is absolutely right, he should h...    False      False   \n",
              "\n",
              "   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  IsNationalist  \\\n",
              "0     False          False      False         False     False          False   \n",
              "1     False          False      False         False     False          False   \n",
              "2     False          False       True         False     False          False   \n",
              "3     False          False      False         False     False          False   \n",
              "4     False          False      False         False     False          False   \n",
              "\n",
              "   IsSexist  IsHomophobic  IsReligiousHate  IsRadicalism  \n",
              "0     False         False            False         False  \n",
              "1     False         False            False         False  \n",
              "2     False         False            False         False  \n",
              "3     False         False            False         False  \n",
              "4     False         False            False         False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75e05c93-8fef-4f7b-b4bc-d844575efd66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CommentId</th>\n",
              "      <th>VideoId</th>\n",
              "      <th>Text</th>\n",
              "      <th>IsToxic</th>\n",
              "      <th>IsAbusive</th>\n",
              "      <th>IsThreat</th>\n",
              "      <th>IsProvocative</th>\n",
              "      <th>IsObscene</th>\n",
              "      <th>IsHatespeech</th>\n",
              "      <th>IsRacist</th>\n",
              "      <th>IsNationalist</th>\n",
              "      <th>IsSexist</th>\n",
              "      <th>IsHomophobic</th>\n",
              "      <th>IsReligiousHate</th>\n",
              "      <th>IsRadicalism</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
              "      <td>04kJtp6pVXI</td>\n",
              "      <td>If only people would just take a step back and...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
              "      <td>04kJtp6pVXI</td>\n",
              "      <td>Law enforcement is not trained to shoot to app...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
              "      <td>04kJtp6pVXI</td>\n",
              "      <td>\\nDont you reckon them 'black lives matter' ba...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
              "      <td>04kJtp6pVXI</td>\n",
              "      <td>There are a very large number of people who do...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
              "      <td>04kJtp6pVXI</td>\n",
              "      <td>The Arab dude is absolutely right, he should h...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75e05c93-8fef-4f7b-b4bc-d844575efd66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75e05c93-8fef-4f7b-b4bc-d844575efd66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75e05c93-8fef-4f7b-b4bc-d844575efd66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "10rU_LDO_D3u",
        "outputId": "ae470479-f130-4524-a7de-0bf4be06d0c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                CommentId      VideoId  \\\n",
              "995  Ugi5ADt10EdDz3gCoAEC  XRuCW80L9mA   \n",
              "996  Ugifh2DMhBbDkHgCoAEC  XRuCW80L9mA   \n",
              "997  Ugj_plbGBjjzYXgCoAEC  XRuCW80L9mA   \n",
              "998  Ugj0bah1De8xy3gCoAEC  XRuCW80L9mA   \n",
              "999  UgjBJKQSoQMQ6ngCoAEC  XRuCW80L9mA   \n",
              "\n",
              "                                                  Text  IsToxic  IsAbusive  \\\n",
              "995  I remember that they sent in the national defe...    False      False   \n",
              "996  Stats don`t represent the problem. Race baitin...     True      False   \n",
              "997  The quote from the mother... Wow that hit hard...    False      False   \n",
              "998                            this video is so racist    False      False   \n",
              "999      God, the narrator has such an annoying lisp.     False      False   \n",
              "\n",
              "     IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  \\\n",
              "995     False          False      False         False     False   \n",
              "996     False          False      False          True      True   \n",
              "997     False          False      False         False     False   \n",
              "998     False          False      False         False     False   \n",
              "999     False          False      False         False     False   \n",
              "\n",
              "     IsNationalist  IsSexist  IsHomophobic  IsReligiousHate  IsRadicalism  \n",
              "995          False     False         False            False         False  \n",
              "996          False     False         False            False         False  \n",
              "997          False     False         False            False         False  \n",
              "998          False     False         False            False         False  \n",
              "999          False     False         False            False         False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d7dd001-570e-43df-bdae-de33439c6b1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CommentId</th>\n",
              "      <th>VideoId</th>\n",
              "      <th>Text</th>\n",
              "      <th>IsToxic</th>\n",
              "      <th>IsAbusive</th>\n",
              "      <th>IsThreat</th>\n",
              "      <th>IsProvocative</th>\n",
              "      <th>IsObscene</th>\n",
              "      <th>IsHatespeech</th>\n",
              "      <th>IsRacist</th>\n",
              "      <th>IsNationalist</th>\n",
              "      <th>IsSexist</th>\n",
              "      <th>IsHomophobic</th>\n",
              "      <th>IsReligiousHate</th>\n",
              "      <th>IsRadicalism</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Ugi5ADt10EdDz3gCoAEC</td>\n",
              "      <td>XRuCW80L9mA</td>\n",
              "      <td>I remember that they sent in the national defe...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Ugifh2DMhBbDkHgCoAEC</td>\n",
              "      <td>XRuCW80L9mA</td>\n",
              "      <td>Stats don`t represent the problem. Race baitin...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Ugj_plbGBjjzYXgCoAEC</td>\n",
              "      <td>XRuCW80L9mA</td>\n",
              "      <td>The quote from the mother... Wow that hit hard...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Ugj0bah1De8xy3gCoAEC</td>\n",
              "      <td>XRuCW80L9mA</td>\n",
              "      <td>this video is so racist</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>UgjBJKQSoQMQ6ngCoAEC</td>\n",
              "      <td>XRuCW80L9mA</td>\n",
              "      <td>God, the narrator has such an annoying lisp.</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d7dd001-570e-43df-bdae-de33439c6b1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d7dd001-570e-43df-bdae-de33439c6b1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d7dd001-570e-43df-bdae-de33439c6b1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "l22Oe1td_Oa3",
        "outputId": "cee3ffec-23b9-43b8-9055-fa1b2e012fe4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Check out this you tube post. \"Black man goes on an epic rant against Ferguson rioters.\"\\n\\nAlthough his message is delivered with childish, cartoon-ish emotions.... He is one of the very few African American\\'s who gets it.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.iloc[6]['Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSx_oVf6_QUf",
        "outputId": "84b3a3aa-2535-4d9c-b0e5-2cf81a2bac25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsAbusive          False\n",
              "IsThreat           False\n",
              "IsProvocative      False\n",
              "IsObscene          False\n",
              "IsHatespeech        True\n",
              "IsRacist            True\n",
              "IsNationalist      False\n",
              "IsSexist           False\n",
              "IsHomophobic       False\n",
              "IsReligiousHate    False\n",
              "IsRadicalism       False\n",
              "Name: 6, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df[df.columns[4:]].iloc[6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhRIBqK7coy8"
      },
      "source": [
        "1. Preprocesado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EQ9aIE0XgSpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5eb592-4c00-48d0-96ee-189161cf9eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ----------------------\n",
            "absl-py                       1.3.0\n",
            "aeppl                         0.0.33\n",
            "aesara                        2.7.9\n",
            "aiohttp                       3.8.3\n",
            "aiosignal                     1.3.1\n",
            "alabaster                     0.7.12\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.0\n",
            "appdirs                       1.4.4\n",
            "arviz                         0.12.1\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "async-timeout                 4.0.2\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.1.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "Babel                         2.11.0\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.1\n",
            "blis                          0.7.9\n",
            "bokeh                         2.3.3\n",
            "branca                        0.6.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cachetools                    5.2.0\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.9.24\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.2\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.1.1\n",
            "click                         7.1.2\n",
            "clikit                        0.6.2\n",
            "cloudpickle                   1.5.0\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.0.8\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.3\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "crashtest                     0.3.1\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda11x                  11.0.0\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.2\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.32\n",
            "daft                          0.0.4\n",
            "dask                          2022.2.1\n",
            "datascience                   0.17.5\n",
            "db-dtypes                     1.0.4\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.6\n",
            "distributed                   2022.2.1\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.7\n",
            "dnspython                     2.2.1\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.334\n",
            "easydict                      1.10\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.1\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         0.9.0\n",
            "etuples                       0.3.8\n",
            "fa2                           0.3.5\n",
            "fastai                        2.7.10\n",
            "fastcore                      1.5.27\n",
            "fastdownload                  0.0.7\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.16.2\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.8.0\n",
            "firebase-admin                5.3.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.12.1.post1\n",
            "frozenlist                    1.3.3\n",
            "fsspec                        2022.11.0\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               2.8.2\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   2.15.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.3.6\n",
            "google-cloud-bigquery-storage 2.16.2\n",
            "google-cloud-core             2.3.2\n",
            "google-cloud-datastore        2.9.0\n",
            "google-cloud-firestore        2.7.2\n",
            "google-cloud-language         2.6.1\n",
            "google-cloud-storage          2.5.0\n",
            "google-cloud-translate        3.8.4\n",
            "google-colab                  1.0.0\n",
            "google-crc32c                 1.5.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.4.0\n",
            "googleapis-common-protos      1.57.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      2.0.1\n",
            "grpcio                        1.51.1\n",
            "grpcio-status                 1.48.2\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.17.2\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httpstan                      4.6.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "importlib-metadata            4.13.0\n",
            "importlib-resources           5.10.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2022.2.1\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.25\n",
            "jaxlib                        0.3.25+cuda11.cudnn805\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.2.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter-core                  5.1.0\n",
            "jupyterlab-widgets            3.0.3\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.9.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      14.0.6\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.39.1\n",
            "lmdb                          0.99\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.9.1\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.0.1\n",
            "marshmallow                   3.19.0\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-venn               0.11.7\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.7.3\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.0.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multidict                     6.0.3\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.7.0\n",
            "netCDF4                       1.6.2\n",
            "networkx                      2.8.8\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      5.7.16\n",
            "numba                         0.56.4\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.21.6\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.6.0.66\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.2\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pastel                        0.2.1\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.10.0\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "platformdirs                  2.5.4\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.8.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.3\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.5.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.15.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.1\n",
            "proto-plus                    1.22.1\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydantic                      1.10.2\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pylev                         1.4.0\n",
            "pymc                          4.1.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       4.3.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     3.0.9\n",
            "pyrsistent                    0.19.2\n",
            "pysimdjson                    3.2.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        3.3.0\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                7.0.0\n",
            "python-utils                  3.4.5\n",
            "pytz                          2022.6\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        6.0\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post2\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.23.0\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.4.2\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.7.3\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.2\n",
            "seaborn                       0.11.2\n",
            "Send2Trash                    1.8.0\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.5.post1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0.post1\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "soundfile                     0.11.0\n",
            "spacy                         3.4.3\n",
            "spacy-legacy                  3.0.10\n",
            "spacy-loggers                 1.0.3\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.44\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.5\n",
            "statsmodels                   0.12.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.1.0\n",
            "tensorboard                   2.9.1\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.9.2\n",
            "tensorflow-datasets           4.6.0\n",
            "tensorflow-estimator          2.9.0\n",
            "tensorflow-gcs-config         2.9.1\n",
            "tensorflow-gpu                2.9.3\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.28.0\n",
            "tensorflow-metadata           1.11.0\n",
            "tensorflow-probability        0.17.0\n",
            "termcolor                     2.1.1\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "thinc                         8.1.5\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2022.10.10\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.13.0+cu116\n",
            "torchaudio                    0.13.0+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.0\n",
            "torchvision                   0.14.0+cu116\n",
            "tornado                       6.0.4\n",
            "tqdm                          4.64.1\n",
            "traitlets                     5.6.0\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typer                         0.7.0\n",
            "typing-extensions             4.4.0\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.5\n",
            "webargs                       8.2.0\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.38.4\n",
            "widgetsnbextension            3.6.1\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.14.1\n",
            "xarray                        0.20.2\n",
            "xarray-einstats               0.3.0\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.2.0\n",
            "xlwt                          1.3.0\n",
            "yarl                          1.8.2\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "R909dZjXQndp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uSJ8a7LODBsR"
      },
      "outputs": [],
      "source": [
        "X = df['Text']\n",
        "y = df[df.columns[3:]].values.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An-9gmn2f-G_",
        "outputId": "59db2867-c9d4-41b3-f760-4be86eb4e070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 1, 0, ..., 0, 0, 0],\n",
              "       [1, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df[df.columns[3:]].values.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVHp-5Mshtph",
        "outputId": "375edffb-0dbc-478f-877c-91a9a15408cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      If only people would just take a step back and...\n",
              "1      Law enforcement is not trained to shoot to app...\n",
              "2      \\nDont you reckon them 'black lives matter' ba...\n",
              "3      There are a very large number of people who do...\n",
              "4      The Arab dude is absolutely right, he should h...\n",
              "                             ...                        \n",
              "995    I remember that they sent in the national defe...\n",
              "996    Stats don`t represent the problem. Race baitin...\n",
              "997    The quote from the mother... Wow that hit hard...\n",
              "998                              this video is so racist\n",
              "999        God, the narrator has such an annoying lisp. \n",
              "Name: Text, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df['Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_qX5J562i4vK"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES = 200000 #numero de palabaras en el vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "eBwrXhT5jZmN"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DUInlo6el1fa"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF_qYZ3YmzHa",
        "outputId": "c8c67555-9ecd-435a-8af8-73c7a9137e3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([  1, 196, 154,   7, 211])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "vectorizer('Hello world, life is great')[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oPDySX58malt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2d0d2b-7c52-4978-85a8-8b38acc7f1a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'the',\n",
              " 'to',\n",
              " 'and',\n",
              " 'a',\n",
              " 'of',\n",
              " 'is',\n",
              " 'that',\n",
              " 'you',\n",
              " 'in',\n",
              " 'i',\n",
              " 'this',\n",
              " 'are',\n",
              " 'it',\n",
              " 'was',\n",
              " 'they',\n",
              " 'for',\n",
              " 'people',\n",
              " 'black',\n",
              " 'not',\n",
              " 'he',\n",
              " 'have',\n",
              " 'on',\n",
              " 'be',\n",
              " 'all',\n",
              " 'if',\n",
              " 'with',\n",
              " 'police',\n",
              " 'but',\n",
              " 'what',\n",
              " 'like',\n",
              " 'just',\n",
              " 'get',\n",
              " 'his',\n",
              " 'do',\n",
              " 'white',\n",
              " 'as',\n",
              " 'so',\n",
              " 'your',\n",
              " 'no',\n",
              " 'by',\n",
              " 'about',\n",
              " 'would',\n",
              " 'there',\n",
              " 'or',\n",
              " 'at',\n",
              " 'we',\n",
              " 'them',\n",
              " 'up',\n",
              " 'who',\n",
              " 'out',\n",
              " 'their',\n",
              " 'its',\n",
              " 'brown',\n",
              " 'dont',\n",
              " 'an',\n",
              " 'will',\n",
              " 'when',\n",
              " 'officer',\n",
              " 'shot',\n",
              " 'should',\n",
              " 'because',\n",
              " 'more',\n",
              " 'from',\n",
              " 'cop',\n",
              " 'why',\n",
              " 'how',\n",
              " 'one',\n",
              " 'these',\n",
              " 'can',\n",
              " 'my',\n",
              " 'did',\n",
              " 'video',\n",
              " 'then',\n",
              " 'him',\n",
              " 'has',\n",
              " 'some',\n",
              " 'know',\n",
              " 'me',\n",
              " 'man',\n",
              " 'being',\n",
              " 'only',\n",
              " 'cops',\n",
              " 'over',\n",
              " 'guy',\n",
              " 'were',\n",
              " 'had',\n",
              " '\\xa0',\n",
              " 'racist',\n",
              " 'go',\n",
              " 'fuck',\n",
              " 'blacks',\n",
              " 'time',\n",
              " 'right',\n",
              " 'need',\n",
              " 'say',\n",
              " 'race',\n",
              " 'those',\n",
              " 'down',\n",
              " 'shit',\n",
              " 'think',\n",
              " 'off',\n",
              " 'im',\n",
              " 'been',\n",
              " 'back',\n",
              " 'see',\n",
              " 'most',\n",
              " 'make',\n",
              " 'going',\n",
              " 'even',\n",
              " 'than',\n",
              " 'here',\n",
              " 'good',\n",
              " 'still',\n",
              " 'other',\n",
              " 'nothing',\n",
              " 'any',\n",
              " 'want',\n",
              " 'us',\n",
              " 'take',\n",
              " 'got',\n",
              " 'way',\n",
              " 'stupid',\n",
              " 'shoot',\n",
              " 'ferguson',\n",
              " 'much',\n",
              " 'michael',\n",
              " 'look',\n",
              " 'store',\n",
              " 'where',\n",
              " 'truth',\n",
              " 'same',\n",
              " 'really',\n",
              " 'mike',\n",
              " 'fucking',\n",
              " 'cant',\n",
              " 'which',\n",
              " 'own',\n",
              " 'killed',\n",
              " 'every',\n",
              " 'against',\n",
              " 'after',\n",
              " 'run',\n",
              " 'now',\n",
              " 'matter',\n",
              " 'into',\n",
              " 'lives',\n",
              " 'gun',\n",
              " 'very',\n",
              " 'thug',\n",
              " 'thats',\n",
              " 'someone',\n",
              " 'saying',\n",
              " 'life',\n",
              " 'could',\n",
              " 'thank',\n",
              " 'stefan',\n",
              " 'said',\n",
              " 'our',\n",
              " 'media',\n",
              " 'use',\n",
              " 'stop',\n",
              " 'put',\n",
              " 'many',\n",
              " 'hands',\n",
              " 'didnt',\n",
              " 'thing',\n",
              " 'peggy',\n",
              " 'law',\n",
              " 'her',\n",
              " 'case',\n",
              " 'also',\n",
              " 'well',\n",
              " 'person',\n",
              " 'community',\n",
              " 'call',\n",
              " 'america',\n",
              " 'whites',\n",
              " 'love',\n",
              " 'job',\n",
              " 'facts',\n",
              " 'day',\n",
              " 'criminal',\n",
              " 'before',\n",
              " 'lol',\n",
              " 'ass',\n",
              " 'too',\n",
              " 'times',\n",
              " 'tell',\n",
              " 'she',\n",
              " 'real',\n",
              " 'doing',\n",
              " 'does',\n",
              " 'cnn',\n",
              " 'another',\n",
              " 'world',\n",
              " 'wilson',\n",
              " 'street',\n",
              " 'something',\n",
              " 'let',\n",
              " 'kill',\n",
              " 'hate',\n",
              " 'everyone',\n",
              " 'come',\n",
              " 'car',\n",
              " 'believe',\n",
              " 'american',\n",
              " 'work',\n",
              " 'while',\n",
              " 'trying',\n",
              " 'great',\n",
              " 'getting',\n",
              " 'bad',\n",
              " 'away',\n",
              " 'wrong',\n",
              " 'racism',\n",
              " 'protesters',\n",
              " 'please',\n",
              " 'officers',\n",
              " 'never',\n",
              " 'fact',\n",
              " 'anyone',\n",
              " 'always',\n",
              " 'protest',\n",
              " 'maybe',\n",
              " 'live',\n",
              " 'issue',\n",
              " 'high',\n",
              " 'god',\n",
              " 'crime',\n",
              " 'cause',\n",
              " 'care',\n",
              " 'am',\n",
              " 'youre',\n",
              " 'years',\n",
              " 'woman',\n",
              " 'such',\n",
              " 'start',\n",
              " 'mr',\n",
              " 'find',\n",
              " 'big',\n",
              " 'anything',\n",
              " 'understand',\n",
              " 'through',\n",
              " 'situation',\n",
              " 'riot',\n",
              " 'rap',\n",
              " 'point',\n",
              " 'made',\n",
              " 'killing',\n",
              " 'kids',\n",
              " 'kid',\n",
              " 'hes',\n",
              " 'happened',\n",
              " 'evidence',\n",
              " 'doesnt',\n",
              " 'death',\n",
              " 'dead',\n",
              " 'around',\n",
              " '2',\n",
              " 'without',\n",
              " 'violence',\n",
              " 'support',\n",
              " 'story',\n",
              " 'shooting',\n",
              " 'reason',\n",
              " 'innocent',\n",
              " 'happen',\n",
              " 'gets',\n",
              " 'year',\n",
              " 'two',\n",
              " 'side',\n",
              " 'news',\n",
              " 'new',\n",
              " 'making',\n",
              " 'lot',\n",
              " 'looting',\n",
              " 'isnt',\n",
              " 'guys',\n",
              " 'first',\n",
              " 'better',\n",
              " 'weapon',\n",
              " 'u',\n",
              " 'things',\n",
              " 'seems',\n",
              " 'riots',\n",
              " 'public',\n",
              " 'money',\n",
              " 'little',\n",
              " 'lets',\n",
              " 'keep',\n",
              " 'idiot',\n",
              " 'human',\n",
              " 'hard',\n",
              " 'government',\n",
              " 'fire',\n",
              " 'family',\n",
              " 'ever',\n",
              " 'comment',\n",
              " 'bullshit',\n",
              " '1',\n",
              " 'young',\n",
              " 'wish',\n",
              " 'talk',\n",
              " 'respect',\n",
              " 'ran',\n",
              " 'question',\n",
              " 'piece',\n",
              " 'peace',\n",
              " 'once',\n",
              " 'molyneux',\n",
              " 'martin',\n",
              " 'makes',\n",
              " 'justice',\n",
              " 'hope',\n",
              " 'everything',\n",
              " 'dumb',\n",
              " 'country',\n",
              " 'comments',\n",
              " 'actually',\n",
              " 'act',\n",
              " '3',\n",
              " 'yet',\n",
              " 'whole',\n",
              " 'went',\n",
              " 'try',\n",
              " 'sure',\n",
              " 'speak',\n",
              " 'shots',\n",
              " 'says',\n",
              " 'probably',\n",
              " 'needs',\n",
              " 'murder',\n",
              " 'mean',\n",
              " 'masri',\n",
              " 'give',\n",
              " 'city',\n",
              " 'bunch',\n",
              " 'body',\n",
              " 'bitch',\n",
              " 'agree',\n",
              " 'watch',\n",
              " 'wait',\n",
              " 'violent',\n",
              " 'thought',\n",
              " 'self',\n",
              " 'robbery',\n",
              " 'problem',\n",
              " 'must',\n",
              " 'likely',\n",
              " 'jury',\n",
              " 'hubbard',\n",
              " 'criminals',\n",
              " 'children',\n",
              " 'browns',\n",
              " 'bring',\n",
              " 'both',\n",
              " 'blocking',\n",
              " 'assaulted',\n",
              " 'already',\n",
              " '5',\n",
              " 'yourself',\n",
              " 'wonder',\n",
              " 'witness',\n",
              " 'videos',\n",
              " 'unarmed',\n",
              " 'theyre',\n",
              " 'started',\n",
              " 'racial',\n",
              " 'protesting',\n",
              " 'population',\n",
              " 'part',\n",
              " 'old',\n",
              " 'next',\n",
              " 'lost',\n",
              " 'later',\n",
              " 'instead',\n",
              " 'incident',\n",
              " 'ignorant',\n",
              " 'hit',\n",
              " 'guns',\n",
              " 'guess',\n",
              " 'force',\n",
              " 'far',\n",
              " 'etc',\n",
              " 'enough',\n",
              " 'else',\n",
              " 'coming',\n",
              " 'cigars',\n",
              " 'came',\n",
              " 'burn',\n",
              " 'best',\n",
              " 'americans',\n",
              " 'again',\n",
              " 'african',\n",
              " 'war',\n",
              " 'wants',\n",
              " 'used',\n",
              " 'truly',\n",
              " 'told',\n",
              " 'though',\n",
              " 'themselves',\n",
              " 'state',\n",
              " 'shows',\n",
              " 'school',\n",
              " 'sad',\n",
              " 'report',\n",
              " 'pretty',\n",
              " 'peaceful',\n",
              " 'oh',\n",
              " 'nice',\n",
              " 'majority',\n",
              " 'listen',\n",
              " 'jail',\n",
              " 'home',\n",
              " 'gas',\n",
              " 'few',\n",
              " 'feel',\n",
              " 'face',\n",
              " 'dude',\n",
              " 'die',\n",
              " 'culture',\n",
              " 'color',\n",
              " 'arrest',\n",
              " '\\xa0i',\n",
              " 'yes',\n",
              " 'wouldnt',\n",
              " 'traffic',\n",
              " 'taken',\n",
              " 'saw',\n",
              " 'road',\n",
              " 'rioting',\n",
              " 'protestors',\n",
              " 'ppl',\n",
              " 'move',\n",
              " 'mother',\n",
              " 'matters',\n",
              " 'long',\n",
              " 'less',\n",
              " 'information',\n",
              " 'girl',\n",
              " 'gentle',\n",
              " 'gang',\n",
              " 'full',\n",
              " 'fired',\n",
              " 'excuse',\n",
              " 'enforcement',\n",
              " 'defend',\n",
              " 'darren',\n",
              " 'course',\n",
              " 'comes',\n",
              " 'brutality',\n",
              " 'behind',\n",
              " 'bassem',\n",
              " 'ask',\n",
              " 'arrested',\n",
              " 'almost',\n",
              " '6',\n",
              " 'zimmerman',\n",
              " 'yall',\n",
              " 'wow',\n",
              " 'women',\n",
              " 'usa',\n",
              " 'until',\n",
              " 'turn',\n",
              " 'true',\n",
              " 'trayvon',\n",
              " 'theres',\n",
              " 'talking',\n",
              " 'system',\n",
              " 'stuff',\n",
              " 'stopped',\n",
              " 'stole',\n",
              " 'stand',\n",
              " 'sorry',\n",
              " 'single',\n",
              " 'since',\n",
              " 'show',\n",
              " 'seriously',\n",
              " 'seen',\n",
              " 'rest',\n",
              " 'protests',\n",
              " 'problems',\n",
              " 'power',\n",
              " 'poor',\n",
              " 'play',\n",
              " 'pepper',\n",
              " 'pants',\n",
              " 'national',\n",
              " 'music',\n",
              " 'middle',\n",
              " 'micheal',\n",
              " 'mb',\n",
              " 'lean',\n",
              " 'last',\n",
              " 'lady',\n",
              " 'knows',\n",
              " 'idiots',\n",
              " 'id',\n",
              " 'himself',\n",
              " 'hell',\n",
              " 'grand',\n",
              " 'goes',\n",
              " 'giant',\n",
              " 'fucks',\n",
              " 'free',\n",
              " 'found',\n",
              " 'fighting',\n",
              " 'fear',\n",
              " 'either',\n",
              " 'drugs',\n",
              " 'drug',\n",
              " 'done',\n",
              " 'dangerous',\n",
              " 'damn',\n",
              " 'couldnt',\n",
              " 'citizens',\n",
              " 'cannot',\n",
              " 'called',\n",
              " 'boy',\n",
              " 'between',\n",
              " 'arent',\n",
              " '4',\n",
              " '\\xa0and',\n",
              " 'youtube',\n",
              " 'worse',\n",
              " 'wont',\n",
              " 'wanna',\n",
              " 'victim',\n",
              " 'using',\n",
              " 'town',\n",
              " 'towards',\n",
              " 'tired',\n",
              " 'thanks',\n",
              " 'strong',\n",
              " 'streets',\n",
              " 'stealing',\n",
              " 'steal',\n",
              " 'spray',\n",
              " 'speaking',\n",
              " 'skittles',\n",
              " 'set',\n",
              " 'sense',\n",
              " 'second',\n",
              " 'place',\n",
              " 'owner',\n",
              " 'others',\n",
              " 'obviously',\n",
              " 'number',\n",
              " 'might',\n",
              " 'men',\n",
              " 'marijuana',\n",
              " 'living',\n",
              " 'lethal',\n",
              " 'however',\n",
              " 'help',\n",
              " 'heard',\n",
              " 'hear',\n",
              " 'head',\n",
              " 'ground',\n",
              " 'fair',\n",
              " 'exactly',\n",
              " 'entire',\n",
              " 'drivers',\n",
              " 'destroy',\n",
              " 'deal',\n",
              " 'days',\n",
              " 'crimes',\n",
              " 'countries',\n",
              " 'completely',\n",
              " 'communities',\n",
              " 'college',\n",
              " 'caught',\n",
              " 'cars',\n",
              " 'business',\n",
              " 'burning',\n",
              " 'beat',\n",
              " 'attack',\n",
              " 'asses',\n",
              " 'arms',\n",
              " 'answer',\n",
              " 'actions',\n",
              " '\\xa0this',\n",
              " 'ya',\n",
              " 'words',\n",
              " 'word',\n",
              " 'welfare',\n",
              " 'weapons',\n",
              " 'watching',\n",
              " 'wasnt',\n",
              " 'useless',\n",
              " 'under',\n",
              " 'tried',\n",
              " 'treated',\n",
              " 'tear',\n",
              " 'smoking',\n",
              " 'skin',\n",
              " 'seem',\n",
              " 'seeing',\n",
              " 'searched',\n",
              " 'robbing',\n",
              " 'robbed',\n",
              " 'rather',\n",
              " 'raised',\n",
              " 'racists',\n",
              " 'prison',\n",
              " 'president',\n",
              " 'post',\n",
              " 'pd',\n",
              " 'parents',\n",
              " 'opinion',\n",
              " 'ones',\n",
              " 'ok',\n",
              " 'obama',\n",
              " 'non',\n",
              " 'nigga',\n",
              " 'name',\n",
              " 'mad',\n",
              " 'lmao',\n",
              " 'line',\n",
              " 'leave',\n",
              " 'kind',\n",
              " 'justify',\n",
              " 'joe',\n",
              " 'ive',\n",
              " 'isis',\n",
              " 'injuries',\n",
              " 'ill',\n",
              " 'ignorance',\n",
              " 'honestly',\n",
              " 'hold',\n",
              " 'history',\n",
              " 'happens',\n",
              " 'handle',\n",
              " 'hand',\n",
              " 'guilty',\n",
              " 'given',\n",
              " 'freeway',\n",
              " 'folks',\n",
              " 'fine',\n",
              " 'fight',\n",
              " 'eye',\n",
              " 'excuses',\n",
              " 'end',\n",
              " 'encounter',\n",
              " 'drive',\n",
              " 'deserved',\n",
              " 'deserve',\n",
              " 'department',\n",
              " 'cunts',\n",
              " 'crap',\n",
              " 'couple',\n",
              " 'complete',\n",
              " 'clerk',\n",
              " 'charge',\n",
              " 'character',\n",
              " 'change',\n",
              " 'caused',\n",
              " 'buy',\n",
              " 'bs',\n",
              " 'brought',\n",
              " 'block',\n",
              " 'bless',\n",
              " 'attacking',\n",
              " 'armed',\n",
              " 'area',\n",
              " 'apprehend',\n",
              " 'air',\n",
              " '100',\n",
              " 'yeah',\n",
              " 'working',\n",
              " 'witnesses',\n",
              " 'week',\n",
              " 'wanted',\n",
              " 'walking',\n",
              " 'walk',\n",
              " 'vote',\n",
              " 'voice',\n",
              " 'view',\n",
              " 'vid',\n",
              " 'understanding',\n",
              " 'tv',\n",
              " 'trouble',\n",
              " 'trial',\n",
              " 'thinking',\n",
              " 'straight',\n",
              " 'statistics',\n",
              " 'statement',\n",
              " 'son',\n",
              " 'simple',\n",
              " 'sick',\n",
              " 'showed',\n",
              " 'shouldnt',\n",
              " 'serve',\n",
              " 'rubber',\n",
              " 'rogan',\n",
              " 'rob',\n",
              " 'rights',\n",
              " 'research',\n",
              " 'realize',\n",
              " 'rate',\n",
              " 'rapping',\n",
              " 'raise',\n",
              " 'punk',\n",
              " 'poverty',\n",
              " 'pot',\n",
              " 'parent',\n",
              " 'mouth',\n",
              " 'message',\n",
              " 'lyrics',\n",
              " 'loot',\n",
              " 'looking',\n",
              " 'longer',\n",
              " 'local',\n",
              " 'liberal',\n",
              " 'legal',\n",
              " 'left',\n",
              " 'learn',\n",
              " 'lack',\n",
              " 'knew',\n",
              " 'judge',\n",
              " 'jobs',\n",
              " 'itself',\n",
              " 'issues',\n",
              " 'interesting',\n",
              " 'inside',\n",
              " 'held',\n",
              " 'half',\n",
              " 'grow',\n",
              " 'gonna',\n",
              " 'glad',\n",
              " 'garbage',\n",
              " 'friend',\n",
              " 'federal',\n",
              " 'explain',\n",
              " 'event',\n",
              " 'easy',\n",
              " 'each',\n",
              " 'died',\n",
              " 'created',\n",
              " 'control',\n",
              " 'common',\n",
              " 'commit',\n",
              " 'clearly',\n",
              " 'clear',\n",
              " 'class',\n",
              " 'chief',\n",
              " 'charged',\n",
              " 'cases',\n",
              " 'bullets',\n",
              " 'break',\n",
              " 'blm',\n",
              " 'bitches',\n",
              " 'bet',\n",
              " 'become',\n",
              " 'awesome',\n",
              " 'attacked',\n",
              " 'arab',\n",
              " 'animals',\n",
              " 'amen',\n",
              " 'absolutely',\n",
              " 'able',\n",
              " 'wounds',\n",
              " 'workers',\n",
              " 'whats',\n",
              " 'wear',\n",
              " 'wake',\n",
              " 'vice',\n",
              " 'unless',\n",
              " 'twice',\n",
              " 'trained',\n",
              " 'together',\n",
              " 'thugs',\n",
              " 'thinks',\n",
              " 'telling',\n",
              " 'teenager',\n",
              " 'tea',\n",
              " 'taser',\n",
              " 'taking',\n",
              " 'step',\n",
              " 'states',\n",
              " 'stated',\n",
              " 'spread',\n",
              " 'society',\n",
              " 'smerconish',\n",
              " 'smart',\n",
              " 'six',\n",
              " 'simply',\n",
              " 'share',\n",
              " 'section',\n",
              " 'search',\n",
              " 'rounds',\n",
              " 'role',\n",
              " 'rioters',\n",
              " 'ridiculous',\n",
              " 'revolution',\n",
              " 'remember',\n",
              " 'recording',\n",
              " 'record',\n",
              " 'read',\n",
              " 'range',\n",
              " 'races',\n",
              " 'quality',\n",
              " 'putting',\n",
              " 'prove',\n",
              " 'propaganda',\n",
              " 'presented',\n",
              " 'plus',\n",
              " 'phone',\n",
              " 'people\\xa0',\n",
              " 'opportunity',\n",
              " 'open',\n",
              " 'omg',\n",
              " 'officials',\n",
              " 'nonsense',\n",
              " 'none',\n",
              " 'nobody',\n",
              " 'needed',\n",
              " 'n',\n",
              " 'myself',\n",
              " 'muslim',\n",
              " 'murdered',\n",
              " 'ms',\n",
              " 'mostly',\n",
              " 'moron',\n",
              " 'minutes',\n",
              " 'mess',\n",
              " 'mentioned',\n",
              " 'mention',\n",
              " 'means',\n",
              " 'may',\n",
              " 'lose',\n",
              " 'lies',\n",
              " 'kept',\n",
              " 'justified',\n",
              " 'info',\n",
              " 'inequality',\n",
              " 'illegal',\n",
              " 'idea',\n",
              " 'huge',\n",
              " 'house',\n",
              " 'hour',\n",
              " 'hey',\n",
              " 'hero',\n",
              " 'having',\n",
              " 'giving',\n",
              " 'front',\n",
              " 'friends',\n",
              " 'freedom',\n",
              " 'focus',\n",
              " 'finally',\n",
              " 'feet',\n",
              " 'failed',\n",
              " 'extremely',\n",
              " 'except',\n",
              " 'events',\n",
              " 'elected',\n",
              " 'due',\n",
              " 'doubt',\n",
              " 'divide',\n",
              " 'difference',\n",
              " 'devil',\n",
              " 'destroying',\n",
              " 'crazy',\n",
              " 'cost',\n",
              " 'convenience',\n",
              " 'continue',\n",
              " 'consequences',\n",
              " 'childish',\n",
              " 'child',\n",
              " 'causing',\n",
              " 'card',\n",
              " 'camera',\n",
              " 'btw',\n",
              " 'blunt',\n",
              " 'bigger',\n",
              " 'biased',\n",
              " 'bias',\n",
              " 'beginning',\n",
              " 'based',\n",
              " 'backup',\n",
              " 'autopsy',\n",
              " 'attention',\n",
              " 'asked',\n",
              " 'arm',\n",
              " 'anyway',\n",
              " 'anger',\n",
              " 'allowed',\n",
              " 'al',\n",
              " 'actual',\n",
              " 'action',\n",
              " 'accounts',\n",
              " 'abuse',\n",
              " 'wouldve',\n",
              " 'whether',\n",
              " 'whatever',\n",
              " 'weed',\n",
              " 'wearing',\n",
              " 'voted',\n",
              " 'upset',\n",
              " 'united',\n",
              " 'turned',\n",
              " 'tragedy',\n",
              " 'totally',\n",
              " 'took',\n",
              " 'title',\n",
              " 'till',\n",
              " 'three',\n",
              " 'theyd',\n",
              " 'terrorist',\n",
              " 'sword',\n",
              " 'surrendering',\n",
              " 'supposed',\n",
              " 'sue',\n",
              " 'style',\n",
              " 'stolen',\n",
              " 'stef',\n",
              " 'stay',\n",
              " 'starts',\n",
              " 'standing',\n",
              " 'st',\n",
              " 'somebody',\n",
              " 'smoke',\n",
              " 'smh',\n",
              " 'sit',\n",
              " 'similar',\n",
              " 'signs',\n",
              " 'sides',\n",
              " 'shut',\n",
              " 'sharpton',\n",
              " 'shame',\n",
              " 'schools',\n",
              " 'scene',\n",
              " 'sayin',\n",
              " 'rush',\n",
              " 'running',\n",
              " 'result',\n",
              " 'response',\n",
              " 'represent',\n",
              " 'reports',\n",
              " 'reporter',\n",
              " 'reported',\n",
              " 'released',\n",
              " 'ready',\n",
              " 'reaction',\n",
              " 'rational',\n",
              " 'quick',\n",
              " 'pulled',\n",
              " 'pull',\n",
              " 'protecting',\n",
              " 'protect',\n",
              " 'property',\n",
              " 'position',\n",
              " 'political',\n",
              " 'pointing',\n",
              " 'playing',\n",
              " 'plain',\n",
              " 'places',\n",
              " 'picture',\n",
              " 'period',\n",
              " 'perfectly',\n",
              " 'perfect',\n",
              " 'peoples',\n",
              " 'past',\n",
              " 'parts',\n",
              " 'paid',\n",
              " 'office',\n",
              " 'neighborhoods',\n",
              " 'negative',\n",
              " 'models',\n",
              " 'military',\n",
              " 'militarized',\n",
              " 'massive',\n",
              " 'male',\n",
              " 'lying',\n",
              " 'lower',\n",
              " 'louis',\n",
              " 'losers',\n",
              " 'looks',\n",
              " 'looked',\n",
              " 'listening',\n",
              " 'letting',\n",
              " 'least',\n",
              " 'lazy',\n",
              " 'kkk',\n",
              " 'king',\n",
              " 'joke',\n",
              " 'intelligence',\n",
              " 'income',\n",
              " 'hot',\n",
              " 'hospital',\n",
              " 'hop',\n",
              " 'highly',\n",
              " 'hide',\n",
              " 'heads',\n",
              " 'hat',\n",
              " 'handling',\n",
              " 'ha',\n",
              " 'govt',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "vectorizer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Jy3iEe7znJse"
      },
      "outputs": [],
      "source": [
        "vectorized_text = vectorizer(X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OY3Pm0gnhP6",
        "outputId": "f8a3f532-ec8a-489b-ace6-91ed31124128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa7fhysenXdz",
        "outputId": "3f4b4885-5668-4fd2-c116-a0da028ffb24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1000, 1800), dtype=int64, numpy=\n",
              "array([[  26,   82,   18, ...,    0,    0,    0],\n",
              "       [ 169,  447,    7, ...,    0,    0,    0],\n",
              "       [  55,    9, 2944, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   2, 1158,   64, ...,    0,    0,    0],\n",
              "       [  12,   73,    7, ...,    0,    0,    0],\n",
              "       [ 229,    2, 3333, ...,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "vectorized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SsaxhXmen9xl"
      },
      "outputs": [],
      "source": [
        "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QXl71E39pWxO"
      },
      "outputs": [],
      "source": [
        "batch_X, batch_y = dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oD9WafQ2qo66"
      },
      "outputs": [],
      "source": [
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3emfYeesH_D",
        "outputId": "91b7dfd0-8ae5-4b9c-9c27-1323b71a93cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZA1PanlidZqv"
      },
      "outputs": [],
      "source": [
        "train_generator = train.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak02PAFZd0nm",
        "outputId": "58150f07-7e03-48b4-aa47-842fcc7e79d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   8,  175,   61, ...,    0,    0,    0],\n",
              "        [  55,    9, 2944, ...,    0,    0,    0],\n",
              "        [  14,  979,   31, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [  11,  418,  475, ...,    0,    0,    0],\n",
              "        [ 399,  406,    2, ...,    0,    0,    0],\n",
              "        [ 143,   48,   84, ...,    0,    0,    0]]),\n",
              " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "train_generator.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM2uG-e1eLmv"
      },
      "source": [
        "2. Crear modelo secuencial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xaI7F5o8eD4T"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense\n",
        "from keras.layers import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVSekNFLhnEA",
        "outputId": "ee2a11b5-2a02-499d-f58c-90aa2ba0b642"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQoVh5Z6h2jc",
        "outputId": "6cc33653-925f-4939-e85d-66ceb02f7e08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Rp43QCNNfGBB"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# Create the embedding layer \n",
        "model.add(Embedding(MAX_FEATURES+1, 32))\n",
        "# Bidirectional LSTM Layer\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "# Feature extractor Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Final layer \n",
        "model.add(Dense(12, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qsqSlCudlTE3"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam',metrics=['binary_accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping  AAA\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='binary_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "EK7Lxn1y52i4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the keras model on the dataset\n",
        "#history = model.fit(train, epochs=9, validation_data=val)\n",
        "history = model.fit(train, validation_data= val, epochs=500, verbose=0, callbacks=[es, mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwQh_HYb6xi7",
        "outputId": "93f5ced6-042b-45b5-aa9c-f6a272574e9f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: binary_accuracy improved from -inf to 0.85677, saving model to best_model.h5\n",
            "\n",
            "Epoch 2: binary_accuracy improved from 0.85677 to 0.88258, saving model to best_model.h5\n",
            "\n",
            "Epoch 3: binary_accuracy improved from 0.88258 to 0.88352, saving model to best_model.h5\n",
            "\n",
            "Epoch 4: binary_accuracy improved from 0.88352 to 0.89062, saving model to best_model.h5\n",
            "\n",
            "Epoch 5: binary_accuracy improved from 0.89062 to 0.90732, saving model to best_model.h5\n",
            "\n",
            "Epoch 6: binary_accuracy improved from 0.90732 to 0.92614, saving model to best_model.h5\n",
            "\n",
            "Epoch 7: binary_accuracy improved from 0.92614 to 0.93951, saving model to best_model.h5\n",
            "\n",
            "Epoch 8: binary_accuracy improved from 0.93951 to 0.95348, saving model to best_model.h5\n",
            "\n",
            "Epoch 9: binary_accuracy improved from 0.95348 to 0.95561, saving model to best_model.h5\n",
            "\n",
            "Epoch 10: binary_accuracy improved from 0.95561 to 0.95821, saving model to best_model.h5\n",
            "\n",
            "Epoch 11: binary_accuracy improved from 0.95821 to 0.96177, saving model to best_model.h5\n",
            "\n",
            "Epoch 12: binary_accuracy did not improve from 0.96177\n",
            "\n",
            "Epoch 13: binary_accuracy improved from 0.96177 to 0.96650, saving model to best_model.h5\n",
            "\n",
            "Epoch 14: binary_accuracy improved from 0.96650 to 0.96721, saving model to best_model.h5\n",
            "\n",
            "Epoch 15: binary_accuracy improved from 0.96721 to 0.96863, saving model to best_model.h5\n",
            "\n",
            "Epoch 16: binary_accuracy did not improve from 0.96863\n",
            "\n",
            "Epoch 17: binary_accuracy improved from 0.96863 to 0.96922, saving model to best_model.h5\n",
            "\n",
            "Epoch 18: binary_accuracy did not improve from 0.96922\n",
            "\n",
            "Epoch 19: binary_accuracy improved from 0.96922 to 0.97088, saving model to best_model.h5\n",
            "\n",
            "Epoch 20: binary_accuracy did not improve from 0.97088\n",
            "\n",
            "Epoch 21: binary_accuracy improved from 0.97088 to 0.97443, saving model to best_model.h5\n",
            "\n",
            "Epoch 22: binary_accuracy improved from 0.97443 to 0.97550, saving model to best_model.h5\n",
            "\n",
            "Epoch 23: binary_accuracy did not improve from 0.97550\n",
            "\n",
            "Epoch 24: binary_accuracy did not improve from 0.97550\n",
            "\n",
            "Epoch 25: binary_accuracy did not improve from 0.97550\n",
            "\n",
            "Epoch 26: binary_accuracy improved from 0.97550 to 0.97869, saving model to best_model.h5\n",
            "\n",
            "Epoch 27: binary_accuracy improved from 0.97869 to 0.97881, saving model to best_model.h5\n",
            "\n",
            "Epoch 28: binary_accuracy improved from 0.97881 to 0.98023, saving model to best_model.h5\n",
            "\n",
            "Epoch 29: binary_accuracy improved from 0.98023 to 0.98047, saving model to best_model.h5\n",
            "\n",
            "Epoch 30: binary_accuracy improved from 0.98047 to 0.98319, saving model to best_model.h5\n",
            "\n",
            "Epoch 31: binary_accuracy did not improve from 0.98319\n",
            "\n",
            "Epoch 32: binary_accuracy improved from 0.98319 to 0.98355, saving model to best_model.h5\n",
            "\n",
            "Epoch 33: binary_accuracy did not improve from 0.98355\n",
            "\n",
            "Epoch 34: binary_accuracy did not improve from 0.98355\n",
            "\n",
            "Epoch 35: binary_accuracy did not improve from 0.98355\n",
            "\n",
            "Epoch 36: binary_accuracy did not improve from 0.98355\n",
            "\n",
            "Epoch 37: binary_accuracy did not improve from 0.98355\n",
            "\n",
            "Epoch 38: binary_accuracy improved from 0.98355 to 0.98426, saving model to best_model.h5\n",
            "\n",
            "Epoch 39: binary_accuracy improved from 0.98426 to 0.98603, saving model to best_model.h5\n",
            "\n",
            "Epoch 40: binary_accuracy did not improve from 0.98603\n",
            "\n",
            "Epoch 41: binary_accuracy improved from 0.98603 to 0.98698, saving model to best_model.h5\n",
            "\n",
            "Epoch 42: binary_accuracy did not improve from 0.98698\n",
            "\n",
            "Epoch 43: binary_accuracy did not improve from 0.98698\n",
            "\n",
            "Epoch 44: binary_accuracy improved from 0.98698 to 0.98698, saving model to best_model.h5\n",
            "\n",
            "Epoch 45: binary_accuracy improved from 0.98698 to 0.98733, saving model to best_model.h5\n",
            "\n",
            "Epoch 46: binary_accuracy improved from 0.98733 to 0.98875, saving model to best_model.h5\n",
            "\n",
            "Epoch 47: binary_accuracy did not improve from 0.98875\n",
            "\n",
            "Epoch 48: binary_accuracy did not improve from 0.98875\n",
            "\n",
            "Epoch 49: binary_accuracy did not improve from 0.98875\n",
            "\n",
            "Epoch 50: binary_accuracy did not improve from 0.98875\n",
            "\n",
            "Epoch 51: binary_accuracy did not improve from 0.98875\n",
            "\n",
            "Epoch 52: binary_accuracy did not improve from 0.98875\n",
            "\n",
            "Epoch 53: binary_accuracy improved from 0.98875 to 0.99089, saving model to best_model.h5\n",
            "\n",
            "Epoch 54: binary_accuracy improved from 0.99089 to 0.99136, saving model to best_model.h5\n",
            "\n",
            "Epoch 55: binary_accuracy did not improve from 0.99136\n",
            "\n",
            "Epoch 56: binary_accuracy improved from 0.99136 to 0.99349, saving model to best_model.h5\n",
            "\n",
            "Epoch 57: binary_accuracy did not improve from 0.99349\n",
            "\n",
            "Epoch 58: binary_accuracy improved from 0.99349 to 0.99384, saving model to best_model.h5\n",
            "\n",
            "Epoch 59: binary_accuracy did not improve from 0.99384\n",
            "\n",
            "Epoch 60: binary_accuracy improved from 0.99384 to 0.99455, saving model to best_model.h5\n",
            "\n",
            "Epoch 61: binary_accuracy improved from 0.99455 to 0.99503, saving model to best_model.h5\n",
            "\n",
            "Epoch 62: binary_accuracy improved from 0.99503 to 0.99645, saving model to best_model.h5\n",
            "\n",
            "Epoch 63: binary_accuracy did not improve from 0.99645\n",
            "\n",
            "Epoch 64: binary_accuracy did not improve from 0.99645\n",
            "\n",
            "Epoch 65: binary_accuracy did not improve from 0.99645\n",
            "\n",
            "Epoch 66: binary_accuracy did not improve from 0.99645\n",
            "\n",
            "Epoch 67: binary_accuracy did not improve from 0.99645\n",
            "\n",
            "Epoch 68: binary_accuracy did not improve from 0.99645\n",
            "\n",
            "Epoch 69: binary_accuracy improved from 0.99645 to 0.99740, saving model to best_model.h5\n",
            "\n",
            "Epoch 70: binary_accuracy did not improve from 0.99740\n",
            "\n",
            "Epoch 71: binary_accuracy improved from 0.99740 to 0.99787, saving model to best_model.h5\n",
            "\n",
            "Epoch 72: binary_accuracy improved from 0.99787 to 0.99858, saving model to best_model.h5\n",
            "\n",
            "Epoch 73: binary_accuracy did not improve from 0.99858\n",
            "\n",
            "Epoch 74: binary_accuracy did not improve from 0.99858\n",
            "\n",
            "Epoch 75: binary_accuracy improved from 0.99858 to 0.99917, saving model to best_model.h5\n",
            "\n",
            "Epoch 76: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 77: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 78: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 79: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 80: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 81: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 82: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 83: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 84: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 85: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 86: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 87: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 88: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 89: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 90: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 91: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 92: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 93: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 94: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 95: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 96: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 97: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 98: binary_accuracy did not improve from 0.99917\n",
            "\n",
            "Epoch 99: binary_accuracy improved from 0.99917 to 0.99976, saving model to best_model.h5\n",
            "\n",
            "Epoch 100: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 101: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 102: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 103: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 104: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 105: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 106: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 107: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 108: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 109: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 110: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 111: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 112: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 113: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 114: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 115: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 116: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 117: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 118: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 119: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 120: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 121: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 122: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 123: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 124: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 125: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 126: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 127: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 128: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 129: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 130: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 131: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 132: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 133: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 134: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 135: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 136: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 137: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 138: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 139: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 140: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 141: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 142: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 143: binary_accuracy did not improve from 0.99976\n",
            "\n",
            "Epoch 144: binary_accuracy improved from 0.99976 to 1.00000, saving model to best_model.h5\n",
            "\n",
            "Epoch 145: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 146: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 147: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 148: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 149: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 150: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 151: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 152: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 153: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 154: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 155: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 156: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 157: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 158: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 159: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 160: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 161: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 162: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 163: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 164: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 165: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 166: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 167: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 168: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 169: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 170: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 171: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 172: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 173: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 174: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 175: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 176: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 177: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 178: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 179: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 180: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 181: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 182: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 183: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 184: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 185: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 186: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 187: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 188: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 189: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 190: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 191: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 192: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 193: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 194: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 195: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 196: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 197: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 198: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 199: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 200: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 201: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 202: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 203: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 204: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 205: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 206: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 207: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 208: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 209: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 210: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 211: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 212: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 213: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 214: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 215: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 216: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 217: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 218: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 219: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 220: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 221: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 222: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 223: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 224: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 225: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 226: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 227: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 228: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 229: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 230: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 231: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 232: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 233: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 234: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 235: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 236: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 237: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 238: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 239: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 240: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 241: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 242: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 243: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 244: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 245: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 246: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 247: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 248: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 249: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 250: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 251: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 252: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 253: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 254: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 255: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 256: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 257: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 258: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 259: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 260: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 261: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 262: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 263: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 264: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 265: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 266: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 267: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 268: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 269: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 270: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 271: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 272: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 273: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 274: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 275: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 276: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 277: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 278: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 279: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 280: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 281: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 282: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 283: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 284: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 285: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 286: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 287: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 288: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 289: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 290: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 291: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 292: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 293: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 294: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 295: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 296: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 297: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 298: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 299: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 300: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 301: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 302: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 303: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 304: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 305: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 306: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 307: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 308: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 309: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 310: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 311: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 312: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 313: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 314: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 315: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 316: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 317: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 318: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 319: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 320: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 321: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 322: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 323: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 324: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 325: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 326: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 327: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 328: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 329: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 330: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 331: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 332: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 333: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 334: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 335: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 336: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 337: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 338: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 339: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 340: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 341: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 342: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 343: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 344: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 345: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 346: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 347: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 348: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 349: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 350: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 351: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 352: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 353: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 354: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 355: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 356: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 357: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 358: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 359: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 360: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 361: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 362: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 363: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 364: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 365: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 366: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 367: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 368: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 369: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 370: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 371: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 372: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 373: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 374: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 375: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 376: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 377: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 378: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 379: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 380: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 381: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 382: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 383: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 384: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 385: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 386: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 387: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 388: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 389: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 390: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 391: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 392: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 393: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 394: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 395: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 396: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 397: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 398: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 399: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 400: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 401: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 402: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 403: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 404: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 405: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 406: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 407: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 408: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 409: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 410: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 411: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 412: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 413: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 414: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 415: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 416: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 417: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 418: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 419: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 420: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 421: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 422: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 423: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 424: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 425: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 426: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 427: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 428: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 429: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 430: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 431: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 432: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 433: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 434: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 435: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 436: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 437: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 438: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 439: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 440: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 441: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 442: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 443: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 444: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 445: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 446: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 447: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 448: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 449: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 450: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 451: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 452: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 453: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 454: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 455: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 456: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 457: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 458: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 459: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 460: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 461: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 462: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 463: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 464: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 465: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 466: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 467: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 468: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 469: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 470: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 471: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 472: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 473: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 474: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 475: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 476: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 477: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 478: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 479: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 480: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 481: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 482: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 483: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 484: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 485: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 486: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 487: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 488: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 489: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 490: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 491: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 492: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 493: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 494: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 495: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 496: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 497: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 498: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 499: binary_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 500: binary_accuracy did not improve from 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iWQQDKWlu8q",
        "outputId": "f59d3af6-7175-4c61-c989-68de05b4c4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          6400032   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               16640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 12)                1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,492,460\n",
            "Trainable params: 6,492,460\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoojgVRzmhPT",
        "outputId": "f3321987-5d6d-4521-8ef2-eb4d9638d5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "44/44 [==============================] - 4s 95ms/step - loss: 8.2582e-05 - binary_accuracy: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 0.9991\n",
            "Epoch 2/3\n",
            "44/44 [==============================] - 4s 91ms/step - loss: 0.0015 - binary_accuracy: 0.9998 - val_loss: 2.5578e-04 - val_binary_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "44/44 [==============================] - 4s 91ms/step - loss: 0.0107 - binary_accuracy: 0.9974 - val_loss: 0.0119 - val_binary_accuracy: 0.9978\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train, epochs=3, validation_data=val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x-bDy8NnT7q",
        "outputId": "422188a5-3f46-44a6-a051-a7caea4cecfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [8.25817696750164e-05, 0.001496537821367383, 0.010692230425775051],\n",
              " 'binary_accuracy': [1.0, 0.9997633099555969, 0.997395932674408],\n",
              " 'val_loss': [0.004300214815884829,\n",
              "  0.00025577624910511076,\n",
              "  0.01192829292267561],\n",
              " 'val_binary_accuracy': [0.9991319179534912, 1.0, 0.9978299140930176]}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-ZSgll1InbH2"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pq3FwU1ynkVl",
        "outputId": "3f77ed04-4d1f-4027-a4f2-49430eea3d99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDFEGmiUysQh"
      },
      "source": [
        "3. Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9VpOdAPDyh9o"
      },
      "outputs": [],
      "source": [
        "input_text = vectorizer('You freaking suck! I am going to hit you.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uDxK_sCiDeU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469f173c-dc60-4541-b5ca-185d90fe19c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1800,), dtype=int64, numpy=array([   9, 1820, 1117, ...,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0kYgx4EKeY3",
        "outputId": "ef3a1403-8b44-4bd4-f4be-ab6a1dc6f01e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene',\n",
              "       'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', 'IsHomophobic',\n",
              "       'IsReligiousHate', 'IsRadicalism'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "df.columns[3:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "LrIGnGh_L4MH"
      },
      "outputs": [],
      "source": [
        "batch = test.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4mF0vekBMG_x"
      },
      "outputs": [],
      "source": [
        "batch_X, batch_y = test.as_numpy_iterator().next()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AUSf7yNdMVWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16476ef9-675c-4b7f-8035-6bf6e9e76263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAtG0Y8OKMLP",
        "outputId": "61b482f8-6002-451d-ec01-fa39a6d4f18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 687ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "(model.predict(batch_X) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Fo3EvO9pDeFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82d33ed-b32f-4a5d-ddc6-715a6d41a8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n"
          ]
        }
      ],
      "source": [
        "res = model.predict(np.expand_dims(input_text, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hOqNL79U903"
      },
      "source": [
        "4. Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "p0nTJh6VU6iB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "eZ9aSbFpVSG2"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kGUhfBoVx32",
        "outputId": "66704a22-92db-489c-c700-6bcbaf1148c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n"
          ]
        }
      ],
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "  #unpack the batch\n",
        "  X_true, y_true = batch\n",
        "  #make a prediction\n",
        "  yhat = model.predict(X_true)\n",
        "\n",
        "  #flatten the predictions\n",
        "  y_true = y_true.flatten()\n",
        "  yhat= yhat.flatten()\n",
        "\n",
        "  pre.update_state(y_true, yhat)\n",
        "  re.update_state(y_true, yhat)\n",
        "  acc.update_state(y_true, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EY9dt7hXoGb",
        "outputId": "fe58220f-9474-405b-a911-1d23363981e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9754098653793335, Recall:1.0, Accuracy:0.9973958134651184\n"
          ]
        }
      ],
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N746Tk0oZIBD"
      },
      "source": [
        "5. Test and gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3CESNS3ZFUD",
        "outputId": "e1413c62-ed4a-4fff-8d54-8b6c1564a08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.13.0-py3-none-any.whl (13.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 17.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (2.11.3)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[K     |████████████████████████████████| 278 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (7.1.2)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.3)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.23.1-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting paramiko\n",
            "  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.23.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.2.2)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.21.6)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2022.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2) (2.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Collecting starlette==0.22.0\n",
            "  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette==0.22.0->fastapi->gradio) (4.4.0)\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 11.9 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.9.24)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.2-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.5 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.2 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.16.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.7 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->gradio) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.6)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 73.4 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=3f5a8a2e74e674adf10232f953484700e2f0253e0e804f08ee7e08b0172eff59\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=d0d54abc5f99236fc2813ede1842d4cb184dcefcd2bff7b144c778503068f152\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/fc/1c/cf980e6413d3ee8e70cd8f39e2366b0f487e3e221aeb452eb0\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, ffmpy, fastapi, gradio\n",
            "Successfully installed anyio-3.6.2 bcrypt-4.0.1 cryptography-38.0.4 fastapi-0.88.0 ffmpy-0.3.0 gradio-3.13.0 h11-0.12.0 httpcore-0.15.0 httpx-0.23.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.3 paramiko-2.12.0 pycryptodome-3.16.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.22.0 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio jinja2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jlS7iwbeZHJB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "by7qY-55Zt3l"
      },
      "outputs": [],
      "source": [
        "model.save('toxicity.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "xb3mQXznZ-M9"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('toxicity.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DvpLVMopa7ba"
      },
      "outputs": [],
      "source": [
        "imput_str = vectorizer('hey i freaken you!. I am coming for you. I am going to hurt you.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AITE-vJja738",
        "outputId": "0d2dcca5-7e6a-4fde-a11f-d3d3a35b88bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 669ms/step\n"
          ]
        }
      ],
      "source": [
        "res = model.predict(np.expand_dims(imput_str,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6seX0g8CbYjC",
        "outputId": "9c0ce10d-a91c-4177-96fa-932f8ea52a7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99948740e-01, 9.99952435e-01, 4.80996550e-06, 3.75441343e-01,\n",
              "        3.96299629e-06, 1.89166354e-08, 5.14913125e-08, 8.01118893e-11,\n",
              "        1.22090775e-11, 3.70056381e-11, 3.93462096e-10, 4.01199247e-11]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq3-2X7zdili",
        "outputId": "3c4ce7d4-5bd3-4ed8-e75a-8c49a23a88e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene',\n",
              "       'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', 'IsHomophobic',\n",
              "       'IsReligiousHate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "df.columns[3:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "rAzV4kOFbYzc"
      },
      "outputs": [],
      "source": [
        "def score_comment(comment):\n",
        "  vectorized_comment = vectorizer([comment])\n",
        "  results = model.predict(vectorized_comment)\n",
        "\n",
        "  text = ''\n",
        "  for idx,col in enumerate(df.columns[3:]):\n",
        "    text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4B-MCkiLeaXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ec3301-749b-4060-ff13-6d1220d19bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n"
          ]
        }
      ],
      "source": [
        "interface = gr.Interface(fn=score_comment, \n",
        "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
        "                        outputs='text')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "ppRDeV2CfR_9",
        "outputId": "0d1fde28-01e0-4cbf-9dc4-d87eb890dc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://b8a71299c9ecc4fa.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b8a71299c9ecc4fa.gradio.app\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "interface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}